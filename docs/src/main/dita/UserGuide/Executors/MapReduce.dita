<?xml version="1.0" encoding="UTF-8"?>
<!--

    Copyright 2017 StreamSets Inc.

    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
    You may obtain a copy of the License at

        http://www.apache.org/licenses/LICENSE-2.0

    Unless required by applicable law or agreed to in writing, software
    distributed under the License is distributed on an "AS IS" BASIS,
    WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
    See the License for the specific language governing permissions and
    limitations under the License.

-->
<!DOCTYPE concept PUBLIC "-//OASIS//DTD DITA Concept//EN" "concept.dtd">
<concept id="concept_bj2_zlk_fx">
 <title>MapReduce Executor</title>
 <conbody>
  <p><indexterm>MapReduce
                    executor<indexterm>overview</indexterm></indexterm><indexterm>executors<indexterm>MapReduce</indexterm></indexterm>The
            MapReduce executor starts a MapReduce job in HDFS or MapR FS each time it receives an
            event record. Use the MapReduce executor as part of an event stream.</p>
        <p>You can use the MapReduce executor to start a custom job, such as a validation job that
            compares the number of records in files. You can also use the MapReduce executor to
            start a predefined job that converts Avro files to Parquet.</p>
        <p><ph conref="../Reusable_Content/ReusablePhrases.dita#concept_vhs_5tz_xp/MapReduce-Use"/>
            For example, you might use the executor to convert an Avro file to Parquet after the
            Hadoop FS destination closes a file as part of the <xref
                href="../Hive_Drift_Solution/HiveDrift-Overview.dita#concept_phk_bdf_2w">Data Drift
                Synchronization Solution for Hive</xref>. </p>
        <p>Note that the MapReduce executor starts jobs in an external system. It does not monitor
            jobs or wait for the job to complete. The executor becomes available for additional
            processing as soon as it successfully submits the job. </p>
        <p>When you configure the MapReduce executor, you specify connection information and job
            details. For the Avro to Parquet job, you specify details such as the output file
            directory and optional compression codec. For other types of jobs, you enter the
            key-value pairs to use. </p>
        <p>When necessary, you can enable Kerberos authentication and specify a MapReduce user. You
            can also use MapReduce configuration files and add other MapReduce configuration
            properties as needed. </p>
        <p conref="../Reusable_Content/ReusablePhrases.dita#concept_vhs_5tz_xp/p-Executor-EventXref"/>
        <p>For a case study about using the MapReduce executor, see <xref
                href="../Event_Handling/CaseStudy-Parquet.dita#concept_jkm_rnz_kx"/>.</p>
 </conbody>
</concept>

<?xml version="1.0" encoding="UTF-8"?>
<!--

    Copyright 2017 StreamSets Inc.

    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
    You may obtain a copy of the License at

        http://www.apache.org/licenses/LICENSE-2.0

    Unless required by applicable law or agreed to in writing, software
    distributed under the License is distributed on an "AS IS" BASIS,
    WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
    See the License for the specific language governing permissions and
    limitations under the License.

-->
<!DOCTYPE task PUBLIC "-//OASIS//DTD DITA General Task//EN" "generalTask.dtd">
<task id="task_skc_j54_1r">
    <title>Reprocessing Error Records</title>
    <shortdesc>You can use a Directory or Kafka Consumer origin in a error pipeline to reprocess
        error record files. When you reprocess error record files, do not edit or rename the files.
        The origin expects the files as generated by the original pipeline.</shortdesc>
    <taskbody>
        <context>
            <p><indexterm>error records<indexterm>reprocessing</indexterm></indexterm>In the error
                pipeline, include the Directory or Kafka Consumer origin and configure it to use the
                SDC Records data format. The SDC Records data format provides information for
                reprocessing the original records with the necessary error handling. </p>
            <p>The SDC Records data format provides the following information: <ul
                    id="ul_fxk_mbd_br">
                    <li>The original source record, as read by the pipeline that generated the
                        error. Changes to the record that might have occurred within the original
                        pipeline are not preserved.</li>
                    <li>Additional metadata that includes: <ul id="ul_xqh_2bg_cr">
                            <li>The path the record took through the pipeline, including the stage
                                that discarded the record.</li>
                            <li>Information about the error, including the error code and
                                message.</li>
                        </ul></li>
                </ul></p>
            <p>When you create the error pipeline, you can use error and record functions provided
                by the expression language to route different types of error records through
                different transformation logic to resolve the error and write the corrected record
                to destinations. </p>
            <p>For example, your error files contain records with invalid product IDs discarded as a
                required field from the first processor in the pipeline, a Field Filter. They also
                include records discarded by a Field Converter for attempting an invalid data type
                conversion. </p>
            <p>In the error pipeline, you can use a Stream Selector to route the records discarded
                from the Field Filter to a branch that corrects product IDs, and the records
                discarded by the Field Converter to a branch that performs a valid data type
                conversion. </p>
        </context>
    </taskbody>
</task>

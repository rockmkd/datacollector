<?xml version="1.0" encoding="UTF-8"?>
<!--

    Copyright 2017 StreamSets Inc.

    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
    You may obtain a copy of the License at

        http://www.apache.org/licenses/LICENSE-2.0

    Unless required by applicable law or agreed to in writing, software
    distributed under the License is distributed on an "AS IS" BASIS,
    WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
    See the License for the specific language governing permissions and
    limitations under the License.

-->
<!DOCTYPE task PUBLIC "-//OASIS//DTD DITA Task//EN" "task.dtd">
<task id="task_kf1_fgv_cy">
    <title>Configuring Cluster Mesos Streaming for Kafka</title>
    <taskbody>
        <context>
            <p><indexterm>cluster mode<indexterm>configuration for Kafka on
                    Mesos</indexterm></indexterm><indexterm>cluster Mesos streaming
                        mode<indexterm>configuration requirements</indexterm></indexterm>Complete
                the following steps to configure a cluster pipeline to read from a Kafka cluster on
                Mesos:</p>
        </context>
        <steps id="steps_jhp_wgv_cy">
            <step>
                <cmd>Verify the installation of Kafka, Spark Streaming, and Mesos as the cluster
                    manager.</cmd>
            </step>
            <step>
                <cmd>Install the <ph
                        conref="../Reusable_Content/ReusablePhrases.dita#concept_vhs_5tz_xp/pName-long"
                    /> on a Spark and Mesos gateway node.</cmd>
            </step>
            <step
                conref="../Reusable_Content/ReusableSteps.dita#task_kzs_5vz_sq/Cluster-CheckpointStorage-Mesos">
                <cmd/>
            </step>
            <step>
                <cmd
                    conref="../Reusable_Content/ReusableSteps.dita#task_kzs_5vz_sq/cmd-SparkSubmitScript"/>
                <info
                    conref="../Reusable_Content/ReusableSteps.dita#task_kzs_5vz_sq/info-SparkSubmit-Default"/>
                <info>If the script is not in this directory, use the SPARK_SUBMIT_MESOS_COMMAND
                    environment variable to define the location of the script.</info>
                <info
                    conref="../Reusable_Content/ReusableSteps.dita#task_kzs_5vz_sq/info-SparkSubmit-Location"/>
                <info><ph
                        conref="../Reusable_Content/ReusableSteps.dita#task_kzs_5vz_sq/ph-SparkSubmit-example"
                    /><codeblock>export SPARK_SUBMIT_MESOS_COMMAND<ph conref="../Reusable_Content/ReusableSteps.dita#task_kzs_5vz_sq/ph-SparkSubmit-Ex-command"/></codeblock></info>
                <info
                    conref="../Reusable_Content/ReusableSteps.dita#task_kzs_5vz_sq/info-SparkSubmit-Restart"
                />
            </step>
            <step>
                <cmd>In the pipeline properties, on the <wintitle>General</wintitle> tab, set the
                        <uicontrol>Execution Mode</uicontrol> property to <uicontrol>Cluster Mesos
                        Streaming</uicontrol>.</cmd>
            </step>
            <step>
                <cmd>On the <uicontrol>Cluster</uicontrol> tab, enter the required properties for
                    Mesos.</cmd>
            </step>
            <step>
                <cmd>In the pipeline, use a Kafka Consumer origin for cluster mode.</cmd>
                <info>If necessary, select a cluster mode stage library on the
                        <wintitle>General</wintitle> tab of the origin. </info>
            </step>
        </steps>
    </taskbody>
    <related-links>
        <link href="../Pipeline_Configuration/ConfiguringAPipeline.dita#task_xlv_jdw_kq"
            type="topic"/>
        <link href="../Origins/KConsumer.dita#concept_msz_wnr_5q" type="topic"/>
    </related-links>
</task>

<?xml version="1.0" encoding="UTF-8"?>
<!--

    Copyright 2017 StreamSets Inc.

    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
    You may obtain a copy of the License at

        http://www.apache.org/licenses/LICENSE-2.0

    Unless required by applicable law or agreed to in writing, software
    distributed under the License is distributed on an "AS IS" BASIS,
    WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
    See the License for the specific language governing permissions and
    limitations under the License.

-->
<!DOCTYPE concept PUBLIC "-//OASIS//DTD DITA Concept//EN" "concept.dtd">
<concept id="concept_hpm_tns_hz">
 <title>Standalone Pipelines</title>
 <conbody>
        <p><indexterm>Spark Evaluator processor<indexterm>standalone
                pipelines</indexterm></indexterm>When used in a standalone pipeline, the Spark
            Evaluator processor starts a local Spark application. It passes a batch of data to the
            Spark application as a Resilient Distributed Dataset (RDD). The Spark application - or
                <codeph>SparkContext</codeph> - runs as long as the pipeline runs. The Spark
            application submits jobs to the StreamSets Spark Transformer API, processing the data
            and then returning the results and errors back to the pipeline for further processing. </p>
        <p>When you use the Spark Evaluator in a standalone pipeline, define a parallelism value for
            the Spark Evaluator. The Spark application creates this number of partitions for each
            batch of records. The Spark Transformer processes each partition in parallel, and then
            returns the results and errors back to the pipeline.</p>
        <note>When you write your custom Spark application for use in a standalone pipeline, do not
            use the <codeph>RDD.checkpoint()</codeph> method. Checkpointing RDDs when the Spark
            Evaluator is in a standalone pipeline can cause the pipeline to fail.</note>
 </conbody>
</concept>

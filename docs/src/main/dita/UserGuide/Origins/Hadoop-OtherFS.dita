<?xml version="1.0" encoding="UTF-8"?>
<!--

    Copyright 2017 StreamSets Inc.

    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
    You may obtain a copy of the License at

        http://www.apache.org/licenses/LICENSE-2.0

    Unless required by applicable law or agreed to in writing, software
    distributed under the License is distributed on an "AS IS" BASIS,
    WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
    See the License for the specific language governing permissions and
    limitations under the License.

-->
<!DOCTYPE concept PUBLIC "-//OASIS//DTD DITA Concept//EN" "concept.dtd">
<concept id="concept_ogc_xzd_f1b">
 <title>Reading from Other File Systems</title>
 <conbody>
  <p><indexterm>Hadoop FS origin<indexterm>reading from other file
            systems</indexterm></indexterm>The Hadoop FS origin allows you to read from file systems
            other than HDFS using the Hadoop FileSystem interface. For example, you can use the
            Hadoop FS origin to read data from Amazon S3 or Microsoft Azure Data Lake Store for a
            cluster batch pipeline if the origin system has the Hadoop FileSystem interface
            installed.</p>
        <p>To read from a file system other than HDFS, perform the following steps:<ol
                id="ol_n25_tvj_f1b">
                <li>Make sure the Hadoop FileSystem interface is installed on the file system.</li>
                <li>Install all required file system application JAR files as external libraries for
                    the Hadoop FS stage library that you use. See the file system documentation for
                    details about the files to install. For instructions on installing external
                    libraries, see <xref
                        href="../Configuration/ExternalLibs.dita#concept_pdv_qlw_ft"/>.</li>
                <li>When you configure the Hadoop FS origin, specify the appropriate URI for the
                    origin system. For example, instead of hdfs://&lt;authority>, to connect to
                    Azure Data Lake Store, you might use adls://&lt;authority>.</li>
            </ol></p>
 </conbody>
</concept>

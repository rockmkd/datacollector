<?xml version="1.0" encoding="UTF-8"?>
<!--
  Licensed under the Apache License, Version 2.0 (the "License");
  you may not use this file except in compliance with the License.
  You may obtain a copy of the License at
  
      http://www.apache.org/licenses/LICENSE-2.0
      
  Unless required by applicable law or agreed to in writing, software
  distributed under the License is distributed on an "AS IS" BASIS,
  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
  See the License for the specific language governing permissions and
  limitations under the License.
-->
<!DOCTYPE concept PUBLIC "-//OASIS//DTD DITA Concept//EN" "concept.dtd">
<concept id="concept_kff_ykv_lz">
 <title>Case Study: Stop the Pipeline</title>
 <conbody>
  <p><indexterm>dataflow trigger case study<indexterm>stop the
                pipeline</indexterm></indexterm><indexterm>Pipeline Finisher<indexterm>case
                    study</indexterm></indexterm>Say your dataflow topology updates a database table
            daily at 4 am. Rather than have the pipeline process the data in a few minutes and sit
            idle for the rest of the day, you want to kick off the pipeline, have it process all
            data and then stop - just like old school batch processing. And you'd like to have the
            pipeline let you know when it has stopped. </p>
        <p>To do this, simply route the no-more-data event record to the Pipeline Finisher executor
            and configure notification.</p>
        <p>The JDBC Query Consumer, JDBC Multitable Consumer, and Salesforce origins all generate
            the no-more-data event when they finish processing queried data. We'll use the JDBC
            Query Consumer to show a more complex scenario. </p>
        <p>Here's the basic pipeline that reads from a database, performs some processing, and
            writes to HDFS: </p>
        <p><image href="../Graphics/Event-StopPipe-Basic.png" id="image_zy1_kkw_lz" scale="60"/></p>
        <p>To configure the pipeline to stop after processing all available queried data:<ol
                id="ol_ivb_qmw_lz">
                <li>Configure the origin to generate events:<p>On the <wintitle>General</wintitle>
                        tab of the JDBC Query Consumer origin, select the <uicontrol>Produce
                            Events</uicontrol> property. </p><p>The event output stream becomes
                        available:</p><p><image href="../Graphics/Event-StopPipe-Event.png"
                            id="image_b5v_znw_lz" scale="55"/></p><p>The JDBC Query Consumer
                        generates several types of events: query success, query failure, and
                        no-more-data. We know this because you checked the <xref
                            href="../Origins/JDBCConsumer-EventRecord.dita#concept_rzl_s1t_kz">Event
                            Record section</xref> of the JDBC Query Consumer documentation. Every
                        event-generating stage has event details in a similar section. </p><p>The
                        query success and failure events can be useful, so you might use a Stream
                        Selector to route those records to a separate event stream. But let's say we
                        don't care about those events, we just want the no-more-data event to pass
                        to the Pipeline Finisher executor. </p></li>
                <li>Connect the event output stream to the Pipeline Finisher executor. <p>At this
                        point, all events that the origin generates come to the executor. Since the
                        JDBC Query Consumer origin generates multiple event types, this setup might
                        cause the executor to stop the pipeline too soon.</p></li>
                <li>To ensure that only the no-more-data event enters the executor, configure a
                        precondition.<p>With a precondition, only records that meet the specified
                        condition can enter the stage. </p><p>We know that each event record
                        includes the event type in the sdc.event.type record header attribute. So to
                        ensure that only no-more-data events enter the stage, we can use the
                        following expression in the
                    precondition:</p><codeblock>${record:eventType() == 'no-more-data'}</codeblock></li>
                <li>Records that don't meet the precondition go to the stage for error handling, so
                    to avoid storing error records that we don't care about – that is, the query
                    success and failure events – let's also set the <uicontrol>On Record
                        Error</uicontrol> property to <uicontrol>Discard</uicontrol>.<p>So here's
                        the Pipeline Finisher: </p><p><image
                            href="../Graphics/Event-StopPipe-Finisher.png" id="image_ucl_4qw_lz"
                            scale="65"/></p></li>
                <li>Now, to get notified when the Pipeline Finisher stops the pipeline, configure
                    the pipeline to send an email when the pipeline state changes to Finished.
                        <p>You can use this option when <ph
                            conref="../Reusable_Content/ReusablePhrases.dita#concept_vhs_5tz_xp/pName-long"
                        /> is <xref href="../Configuration/SendingEmail.dita#concept_it1_wwg_xz">set
                            up to send email</xref>. You can alternatively use the pipeline state
                        notification to send a webhook, or use an <xref
                            href="../Executors/Email.dita#concept_sjs_sfp_qz">Email executor</xref>
                        in the pipeline to send a customized email. Since we only need a simple
                        notification, let's send a basic email based on the pipeline state: <ol
                            id="ol_wcz_wsb_yz">
                            <li>Click in the canvas to view the pipeline configuration, and click
                                the <wintitle>Notifications</wintitle> tab. </li>
                            <li>In the <uicontrol>Notify on Pipeline State Changes</uicontrol>,
                                leave the <uicontrol>Finished</uicontrol> state and remove the other
                                default states. </li>
                            <li>Then, enter the email addresses to receive the email:</li>
                        </ol></p><p><image href="../Graphics/Event-StopPipe-Notification.png"
                            id="image_qmr_cpv_xz" scale="60"/></p></li>
            </ol>That's it!</p>
        <p>With this setup, the JDBC Query Consumer passes a no-more-data event when it completes
            processing all data returned by the query, and the Pipeline Finisher executor stops the
            pipeline and transitions the pipeline to a Finished state. All other events generated by
            the origin are discarded. <ph
                conref="../Reusable_Content/ReusablePhrases.dita#concept_vhs_5tz_xp/pName-long"/>
            sends notification so you know when the pipeline finishes, and the next time you want to
            process more data, you can just start the pipeline again. </p>
 </conbody>
</concept>

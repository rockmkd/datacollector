<?xml version="1.0" encoding="UTF-8"?>
<!--
  Licensed under the Apache License, Version 2.0 (the "License");
  you may not use this file except in compliance with the License.
  You may obtain a copy of the License at
  
      http://www.apache.org/licenses/LICENSE-2.0
      
  Unless required by applicable law or agreed to in writing, software
  distributed under the License is distributed on an "AS IS" BASIS,
  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
  See the License for the specific language governing permissions and
  limitations under the License.
-->
<!DOCTYPE concept PUBLIC "-//OASIS//DTD DITA Concept//EN" "concept.dtd">
<concept id="concept_rxg_shn_lx">
 <title>Executors</title>
 <conbody>
        <p>
            <indexterm>event framework<indexterm>executors</indexterm></indexterm>Executors perform
            tasks when they receive event records. You can use the following executor stages for
            event handling:<dl>
                <dlentry>
                    <dt>Hive Query executor</dt>
                    <dd>Executes user-defined Hive or Impala queries for each event.</dd>
                    <dd>Use with the Hive Metadata destination to run Hive or Impala queries after
                        Hive metastore updates. You can also use the executor with the Hadoop FS or
                        MapR FS destinations to run queries after closing files. </dd>
                    <dd>For example, you might use the Hive Query executor as part of the Drift
                        Synchronization Solution for Hive if you read data with Impala. Impala
                        requires you to run the Invalidate Metadata command when the table structure
                        or data changes. </dd>
                    <dd>Instead of trying to time this action manually, you can use the Hive Query
                        executor to submit the command automatically each time the Hive Metastore
                        destination changes the structure of a table and each time the Hadoop FS
                        destination closes a file. </dd>
                </dlentry>
                <dlentry>
                    <dt>HDFS File Metadata executor</dt>
                    <dd>Creates an empty file or changes the metadata for an existing file upon
                        receiving an event. When creating an empty file, the executor can specify
                        the owner and group and set permissions and ACLs for the file. When changing
                        file metadata, the executor can rename and move files in addition to
                        specifying the owner and group, and updating permissions and ACLs for files. </dd>
                    <dd>You can use the executor in any logical way, but it is optimized to change
                        file metadata after receiving file closure events from the Hadoop FS, Local
                        FS, and MapR FS destinations. </dd>
                    <dd>For example, you can use the HDFS File Metadata executor with the Mapr FS
                        destination to move and change the permissions of files when the destination
                        closes a file.</dd>
                </dlentry>
                <dlentry>
                    <dt>Pipeline Finisher executor</dt>
                    <dd>Stops the pipeline when it receives an event, transitioning the pipeline to
                        a Finished state.</dd>
                    <dd>Use with the no-more-data events generated by the JDBC Query Consumer, JDBC
                        Multitable Consumer, or Salesforce origins to achieve "batch" processing -
                        stopping the pipeline when all available data is processed rather than
                        leaving the pipeline to sit idle indefinitely. </dd>
                    <dd>For example, you might use the Pipeline Finisher executor with the JDBC
                        Multitable Consumer to stop the pipeline when it processes all queried data
                        in the specified tables.</dd>
                </dlentry>
                <dlentry>
                    <dt>JDBC Query executor</dt>
                    <dd>Connects to a database using JDBC and runs the specified SQL query. </dd>
                    <dd>Use to run a SQL query on a database after an event occurs.</dd>
                </dlentry>
                <dlentry>
                    <dt>MapReduce executor</dt>
                    <dd>Connects to HDFS or MapR FS and starts a MapReduce job for each event. </dd>
                    <dd>Use with the Hadoop FS or MapR FS destinations to run MapReduce jobs on
                        closed files. </dd>
                    <dd>For example, you can use the MapReduce executor with the Hadoop FS
                        destination to convert Avro files to Parquet when Hadoop FS closes a file.
                    </dd>
                </dlentry>
                <dlentry>
                    <dt>Spark executor</dt>
                    <dd>Connects to Spark on YARN or Databricks and starts a Spark application for
                        each event.</dd>
                    <dd>Use with the Hadoop FS, MapR FS, or Amazon S3 destination to run Spark
                        applications on closed files.</dd>
                    <dd>For example, you can use the Spark executor with the Hadoop FS destination
                        to convert Avro files to Parquet when Hadoop FS closes a file. </dd>
                </dlentry>
            </dl></p>
 </conbody>
</concept>

<?xml version="1.0" encoding="UTF-8"?>
<!--
  Licensed under the Apache License, Version 2.0 (the "License");
  you may not use this file except in compliance with the License.
  You may obtain a copy of the License at
  
      http://www.apache.org/licenses/LICENSE-2.0
      
  Unless required by applicable law or agreed to in writing, software
  distributed under the License is distributed on an "AS IS" BASIS,
  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
  See the License for the specific language governing permissions and
  limitations under the License.
-->
<!DOCTYPE concept PUBLIC "-//OASIS//DTD DITA Concept//EN" "concept.dtd">
<concept id="concept_azz_tq4_lx">
 <title>Summary</title>
 <conbody>
        <p><indexterm>dataflow triggers<indexterm>summary</indexterm></indexterm><indexterm>event
                    framework<indexterm>summary</indexterm></indexterm>Here's are the key points
            about dataflow triggers and the event framework: <ol id="ol_fz4_ygh_tx">
                <li>You can use the event framework to any pipeline that includes a stage that
                    generates events. </li>
                <li>The event-generating stage generates events at logical moments related to stage
                    processing, such as the closing of a file.</li>
                <li>When generating an event, the stage creates an <term>event record</term> that
                    contains relevant information regarding the event, such as the path to the file
                    that was closed. <p><ph
                            conref="../Reusable_Content/ReusablePhrases.dita#concept_vhs_5tz_xp/ph-ERecord-Fields"
                        /></p></li>
                <li>In the simplest use case, you can route event records to a destination to save
                    event information.</li>
                <li>You can also use event records as dataflow triggers - to perform tasks like
                    changing permissions for closed files, starting a MapReduce job, or stopping the
                    pipeline.</li>
                <li>To trigger a task, connect the event stream to an executor stage.<p>For a list
                        of logical event generation and executor pairings, see <xref
                            href="LogicalPairings.dita#concept_scs_3hh_tx"/>.</p></li>
                <li>When necessary, you can add processors to the event stream.<p>For example, you
                        might add an Expression Evaluator to add the event generation time to an
                        event record before writing it to a destination. Or, you might use a Stream
                        Selector to route different types of event records to different
                        executors.</p></li>
                <li>You cannot merge event streams with data streams. </li>
                <li>You can use the Dev Data Generator and To Event development stages to generate
                    events for pipeline development and testing. For more information about the
                    development stages, see <xref
                        href="../Pipeline_Design/DevStages.dita#concept_czx_ktn_ht"/>.</li>
                <li>In data preview, when reviewing snapshots of data, and in Monitor mode, event
                    records display as event records in the record-generating stage. Afterwards they
                    are treated like any standard record. </li>
            </ol> For examples of how you might use the event framework, see the case studies
            earlier in this chapter. </p>
 </conbody>
</concept>
